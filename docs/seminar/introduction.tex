\section{Introduction}
\label{sec:introduction}
The goal of expertise retrieval is to link humans to expertise areas, and vice versa. In other words, the task of expertise retrieval is to identify a set of persons with relevant expertise for the given query \cite{er,er-community-aware}.

With the development of information retrieval (IR) techniques, many research efforts go beyond traditional document retrieval and address high-level IR such as entity retrieval and expertise retrieval \cite{er-sparse}. The launch of the Expert Finding task at TREC has generated a lot of interest in expertise retrieval, following by rapid progress being made in terms of modeling, algorithms, and evaluation aspects \cite{trec2005,er-community-aware}.

\cite{trec2005} propose two principal approaches  in the expertise retrieval area based on probabilistic language modeling techniques. They were formalized as so-called \textit{candidate models} and \textit{document models}. The candidate-based approach, also referred to as profile-based method, builds a textual representation of candidate experts and then ranks them based on the query. The document models first find documents relevant to the topic and then locate the experts associated with these documents \cite{er}.

Ranking techniques are an essential part of each IR framework. In recent years, Learning to Rank (L2R) has been studied extensively especially for document retrieval. It refers to machine learning techniques for training the model in a ranking task \cite{er}. In essence, expert search is a ranking problem and thus the existing L2R techniques can be naturally applied to it \cite{l2r-intro}.

As well as ranking techniques, aggregation functions have a significant effect on the performance of expert retrieval systems. Aggregate tasks are those where documents' similarities are not
the final outcome, but instead an intermediary component. In expert search, a ranking of candidate persons with relevant expertise to a query is generated after aggregation of their related documents \cite{agg-learning}.

This paper addresses the problem of searching translators as experts. We offer a novel translator-expert retrieval platform and evaluate different expert retrieval methods based on the practical implementation of the platform. In contrast to common expert retrieval systems, we include significant factors of searching a translator (like price and delivery time) in the study as well as the relevance of the documents to the query document. We have applied Learning to Rank in a candidate-based approach. Additionally, different aggregation algorithms related to documents of translators have been studied and compared.

The remaining of the paper is organized as follows. In Section\ref{sec:casestudy}, the Translator-Expert Retrieval framework is described in detail. Then, Section\ref{sec:methods} explains methods used in the study. In Section\ref{sec:apply}, we report the result of applied methods on the framework. Finally, we conclude the study in Section\ref{sec:conclusion}.
