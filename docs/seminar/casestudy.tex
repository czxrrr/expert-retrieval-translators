\section{Case Study}
\label{sec:casestudy}
Essential components of the platform as well as the work-flow of searching for the translators are depicted in Figure \ref{fig:architecture}. The platform consist of four main components: \textit{Ranking}, \textit{Proficiency Estimator}, \textit{Scheduler} and \textit{Profiles}.

\begin{figure*}[h]
\begin{center}
\includegraphics[scale=0.8]{figures/dataflow.png}
\caption{Translator-Expert Search Work Flow
\label{fig:architecture}}
\end{center}
\end{figure*}

The \textit{Profiles} stores translator profile information i.e. source and target languages, offered price and translation duration per word. The \textit{Scheduler} system figures out the delivery time based on timetable of translators. The scheduler builds an efficient data structure to calculate the delivery time in a reasonable response time. The details of the process are out of scope of the paper. The \textit{Proficiency Estimator} system stores the previous-translated documents and indexes them using Lucene. The similarity between query and indexed documents is used as a basis for the estimation of translator's proficiency. In fact, the proficiency value is achieved by aggregating the documents similarity scores. The applied aggregation function is described in Section\ref{sec:apply}. At last, the \textit{Ranking} system uses all the data provided in the previous steps to create the ranking model. The \textit{Ranking} system applies Learning to Rank techniques to return the most related translators to the client. The training data is provided by a group of annotators who are familiar with the business of company using an evaluation system. The evaluation system suggests three translators and the annotators rate them by comparing between their factors. In order to prevent bias in evaluation, the translators are suggested randomly and without name and picture. Applied learning to rank methods and results are described in Section\ref{sec:apply}. 

The client submits a document and searches for translators with a specific target language. Based on the query document, the framework figures out the offered price, delivery time, proficiency of translators as well as the number of cooperation times related to each translator. The ranking system processes the calculated values and offers the most related translators to the client.

Beside the mentioned work-flow after finishing the translation, another expert called proofreader revises the translation. The proofreader is selected by the client and guarantees the quality of the final translation. As well as revising, the proofreader assesses the quality of translator's task from different points of view (grammar, style, accuracy, content and language). The assessment value can be from $1$ (very bad) to $5$ (perfect). As it is described in Section\ref{sec:apply}, we use these assessments to evaluate and compare aggregation algorithms.
