\section{Apply The Methods and Results}
\label{sec:apply}
In this section, we applied different approaches on the platform. By comparing the methods, we aim to discover the most appropriate one regarding to the project's characteristics and data.

\subsection{Aggregation Functions}
In order to compare different aggregation functions, similar to \citet{agg-gp2} three algorithms are selected. $GP2$ as well as $Top1$ and $Top5$ which are two common forms of $TopN$ aggregation algorithm. $TopN$ refers to algorithm that summarizes the $N$ top documents (i.e. $Top1$ only using the top associated document to rank the candidates).

Feedbacks of proof-readers after every translation are used as a basis for evaluating the algorithms. Since feedbacks are a measure for quality of translation, the more similar the ranking of algorithms to feedbacks are the better it is. 

The calculation is done based on $181$ records of purchased orders. The coefficient values of applying Pearson Correlation ($r$) and Spearman's Rank Order Correlation ($r_s$) are shown in Table \ref{table:Spearman}. TODO: Significance Test . 

The outcome shows an approximately weak correlation between aggregation functions and feedbacks of proof-readers. Nevertheless among the introduced algorithms, $GP2$ outperforms the others. In comparison to $Top1$, $Top5$ has slightly better performance. The results are also nearly the same when comparing based on language-pairs.

\begin{table}
\begin{center}
\scalebox{1.2}{
\begin{tabular}{p{1cm}|c|c|c|}
\cline{2-4} & Top1 & Top5 & GP2  \\
\hline \multicolumn{1}{ |c| }{$r$} & 0.018 & 0.063 & 0.117\\
\hline \multicolumn{1}{ |c| }{$r_s$} & 0.052 & 0.087 & 0.145\\
\hline
\end{tabular}
}
\caption{Comparison between algorithms and feedbacks}
\label{table:Spearman}
\end{center}
\end{table}

\subsection{Learning To Rank}
TODO